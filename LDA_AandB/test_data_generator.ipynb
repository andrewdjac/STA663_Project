{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dists(alpha, beta, M, K, V):\n",
    "    \"\"\"Generates topic and word distributions\"\"\"\n",
    "    \n",
    "    # Generate word distributions\n",
    "    phi = np.zeros((K, V))\n",
    "    for k in range(K):\n",
    "        phi[k, :] = np.random.dirichlet(beta)\n",
    "    \n",
    "    # Generate topic distributions\n",
    "    theta = np.zeros((M, K))\n",
    "    for m in range(M):\n",
    "        theta[m,:] = np.random.dirichlet(alpha)\n",
    "    \n",
    "    return((phi, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(phi, theta, M, N_min, N_max):\n",
    "    \"\"\"Generates 'words' for corpus\"\"\"\n",
    "    \n",
    "    doc_lens = np.random.randint(N_min, N_max, M)\n",
    "    z = {}\n",
    "    w = {}\n",
    "    for m in range(M):\n",
    "        z[m] = []\n",
    "        w[m] = []\n",
    "        for n in range(doc_lens[m]):\n",
    "            z[m].extend(np.nonzero(np.random.multinomial(1, theta[m,:]))[0])\n",
    "            w[m].extend(np.nonzero(np.random.multinomial(1, phi[z[m][n], :]))[0])\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow(w, M, V):\n",
    "    \"\"\"Creates bag-of-words matrix from corpus\"\"\"\n",
    "    \n",
    "    bow = np.zeros((M, V))\n",
    "    for m in range(M):\n",
    "        for v in range(V):\n",
    "            bow[m, v] = len(np.where(np.array(w[m]) == v)[0])\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_corpus(alpha, beta, M, N_min, N_max):\n",
    "    \"\"\"Generates test data for LDA\"\"\"\n",
    "    \n",
    "    # Get corpus parameters\n",
    "    K = len(alpha)\n",
    "    V = len(beta)\n",
    "    \n",
    "    # Generate topic and word distributions\n",
    "    phi, theta = generate_dists(alpha, beta, M, K, V)\n",
    "    \n",
    "    # Generate words\n",
    "    w = generate_words(phi, theta, M, N_min, N_max)\n",
    "    \n",
    "    # Make bag-of-words matrix\n",
    "    bow = make_bow(w, M, V)\n",
    "    \n",
    "    return((bow, phi, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newsgroups(categories = None, n_articles = 10):\n",
    "    \"\"\"Fetches random newsgroups articles of specified categories\"\"\"\n",
    "    \n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "    newsgroups = fetch_20newsgroups(subset = 'train', remove = remove, categories = categories)\n",
    "    \n",
    "    ind = np.random.choice(len(newsgroups.data), size = n_articles, replace = False)\n",
    "    news = [newsgroups.data[i] for i in ind]\n",
    "    labels = [newsgroups.target[i] for i in ind]\n",
    "    \n",
    "    words = [' '.join(filter(str.isalpha, raw.lower().split())) for raw in\n",
    "        news]\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(words)\n",
    "    bow_sparse = vectorizer.transform(words)\n",
    "    bow = np.array(csr_matrix.todense(bow_sparse))\n",
    "    \n",
    "    return (bow, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 1, 1],\n",
       "        [5, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 1, 2, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 2, 0]]), [17, 16, 0, 12, 1, 7, 11, 10, 14, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
