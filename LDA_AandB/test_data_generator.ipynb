{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dists(alpha, beta, M, K, V):\n",
    "    \"\"\"Generates topic and word distributions\"\"\"\n",
    "    \n",
    "    # Generate word distributions\n",
    "    phi = np.zeros((K, V))\n",
    "    for k in range(K):\n",
    "        phi[k, :] = np.random.dirichlet(beta)\n",
    "    \n",
    "    # Generate topic distributions\n",
    "    theta = np.zeros((M, K))\n",
    "    for m in range(M):\n",
    "        theta[m,:] = np.random.dirichlet(alpha)\n",
    "    \n",
    "    return((phi, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(phi, theta, M, N_min, N_max):\n",
    "    \"\"\"Generates 'words' for corpus\"\"\"\n",
    "    \n",
    "    doc_lens = np.random.randint(N_min, N_max, M)\n",
    "    z = {}\n",
    "    w = {}\n",
    "    for m in range(M):\n",
    "        z[m] = []\n",
    "        w[m] = []\n",
    "        for n in range(doc_lens[m]):\n",
    "            z[m].extend(np.nonzero(np.random.multinomial(1, theta[m,:]))[0])\n",
    "            w[m].extend(np.nonzero(np.random.multinomial(1, phi[z[m][n], :]))[0])\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow(w, M, V):\n",
    "    \"\"\"Creates bag-of-words matrix from corpus\"\"\"\n",
    "    \n",
    "    bow = np.zeros((M, V))\n",
    "    for m in range(M):\n",
    "        for v in range(V):\n",
    "            bow[m, v] = len(np.where(np.array(w[m]) == v)[0])\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_corpus(alpha, beta, M, N_min, N_max):\n",
    "    \"\"\"Generates test data for LDA\"\"\"\n",
    "    \n",
    "    # Get corpus parameters\n",
    "    K = len(alpha)\n",
    "    V = len(beta)\n",
    "    \n",
    "    # Generate topic and word distributions\n",
    "    phi, theta = generate_dists(alpha, beta, M, K, V)\n",
    "    \n",
    "    # Generate words\n",
    "    w = generate_words(phi, theta, M, N_min, N_max)\n",
    "    \n",
    "    # Make bag-of-words matrix\n",
    "    bow = make_bow(w, M, V)\n",
    "    \n",
    "    return((bow, phi, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newsgroups(categories = None, n_articles = 10):\n",
    "    \"\"\"Fetches random newsgroups articles of specified categories\"\"\"\n",
    "    \n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "    newsgroups = fetch_20newsgroups(subset = 'train', remove = remove, categories = categories)\n",
    "    \n",
    "    ind = np.random.choice(len(newsgroups.data), size = n_articles, replace = False)\n",
    "    news = [newsgroups.data[i] for i in ind]\n",
    "    labels = [newsgroups.target[i] for i in ind]\n",
    "    \n",
    "    words = [' '.join(filter(str.isalpha, raw.lower().split())) for raw in\n",
    "        news]\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(words)\n",
    "    wordbank = vectorizer.get_feature_names()\n",
    "    \n",
    "    bow_sparse = vectorizer.transform(words)\n",
    "    bow = np.array(csr_matrix.todense(bow_sparse))\n",
    "    \n",
    "    return (bow, labels, wordbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ('headers', 'footers', 'quotes')\n",
    "newsgroups = fetch_20newsgroups(subset = 'train', remove = remove, categories = ['comp.graphics', 'soc.religion.christian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(len(newsgroups.data), size = 3, replace = False)\n",
    "news = [newsgroups.data[i] for i in ind]\n",
    "labels = [newsgroups.target[i] for i in ind]\n",
    "words = [' '.join(filter(str.isalpha, raw.lower().split())) for raw in\n",
    "        news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so does that mean that anyone who is a christian to avoid hell really a christian at it sounds like it to mit liebe in martyn martyn department of applied mathematics and theoretical the university of box ergo deus',\n",
       " 'hi i am looking for a polygon fill routine to fill simple sided polygons can some one who has this routine in c help me in saving my thanx in advance',\n",
       " 'a question for you can you give me the name of an organization or a philosophy or a political which has never had anything evil done in its missing a central teaching of christianity man is inherently we are saved through faith by knowing believing does not make us without not all who consider themselves are those who manage to head their own everyone who says to will enter the kingdom of but only he who does the will of my father who is in what historical documents do you do you think hannibal crossed the how do you how do you know for what historical documents have stood the scrutiny and the attempts to credit it as well as the bible really a shame you feel this no one can browbeat you into and those who try will probably only succeed in driving you further you need to ask yourself some difficult is there an and if does man require salvation to attain if the answer is the next question is how does man attain this salvation can he do it on his own as the eastern religions and certain modern offshoots like the age teach or does he require if the in what form does in what form can such help needless to this discussion could take a and for some people it did comprise their so i am hardly in a position to offer the answers here merely pointers to what to of us manage to have an unshaken faith our entire lives not the spritual life is a difficult journey never read i highly recommend this greatest allegory of the english now i see by your close that one possible source of trouble for you may be a conflict between your politcal beliefs and your religious you wrote that my own accept and live my life by many if not most of the teachings of christ referred to god as not and while the of god is not the same as the maleness of those of us humans who possess a y it does not honor god to refer to him as female purely to be or politically this in no way disparages women is it my intent to do so by my use of the male pronoun to refer to both men and women english just does not have a decent neuter set of after god chose a woman as his only human partner in bringing christ into the human not about to launch into a detailed discussion of the role of women in christianity at with only hours of sleep in the last and for that reason i also apologize for any shortcomings in this i just happened across yours and felt moved to i hope i may have given and anyone else who finds himself in a similar frame of something to']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(words)\n",
    "vectorizer.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0916970e65c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
